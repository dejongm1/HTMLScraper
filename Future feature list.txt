Future feature list

getRecords()
	crawl randomly, rotate IPs ---- already trying crawl slowly, rotate User-agents
	On failed getHtmlAsDoc(baseDoc) getHtmlAsDoc(resultsPage), retry 3 times with different user-agent
	On failed getHtmlAsDoc(recordDetail) retry once, keeping track of failed pages
		- save to list or retry immediately?
	After so many failed getHtmlAsDoc()s stop trying
	
	Send e-mail when finished
	
	Don't override spreadsheet each run
	One spreadsheet per state if running for multiple
	
	Only save to spreadsheet if it's not found already
		- running every week will stop if we reach previous records
		- need to save spreadsheet if we do it this way
	
	Start where we left off? Not sure how I would do that
		- keep track of the page we're on? we would only retry a certain number of records
		- output more info per record to spreadsheet. Read the spreadsheet in first, then start there
		



Constants class for messages
Search for specific word(s)
	- variations of those words

Exclude special characters (and numbers?)
Add help documentation
Result exclusion file for frequent words
	- flag for excluding common words (the, a, and, of, in, etc)
	- flag for including numbers
	- add to/remove from list


Traverse a sites pages
	- specified level deep
	- complete site (possible by domain?)
	- find all <a href=>

If website can't be reached with http://, try https://

